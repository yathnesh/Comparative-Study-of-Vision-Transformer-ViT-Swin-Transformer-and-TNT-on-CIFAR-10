{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and preprocess the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to range [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Split training set into training and validation sets\n",
    "val_size = int(0.2 * x_train.shape[0])\n",
    "x_val = x_train[:val_size]\n",
    "y_val = y_train[:val_size]\n",
    "x_train = x_train[val_size:]\n",
    "y_train = y_train[val_size:]\n",
    "\n",
    "# Define patch size\n",
    "PATCH_SIZE = 2  # Each patch is 2x2 pixels\n",
    "\n",
    "# Function to split an image into patches\n",
    "def extract_patches(images, patch_size):\n",
    "    batch_size = tf.shape(images)[0]\n",
    "    patches = tf.image.extract_patches(\n",
    "        images=images,\n",
    "        sizes=[1, patch_size, patch_size, 1],\n",
    "        strides=[1, patch_size, patch_size, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding='VALID'\n",
    "    )\n",
    "    patch_dim = patch_size * patch_size * 3\n",
    "    patches = tf.reshape(patches, [batch_size, -1, patch_dim])\n",
    "    return patches\n",
    "\n",
    "# Apply patch extraction to training, validation, and test data\n",
    "train_patches = extract_patches(x_train, PATCH_SIZE)\n",
    "val_patches = extract_patches(x_val, PATCH_SIZE)\n",
    "test_patches = extract_patches(x_test, PATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(num_patches, dim):\n",
    "    positions = np.arange(num_patches)[:, np.newaxis]\n",
    "    dimensions = np.arange(dim)[np.newaxis, :]\n",
    "    angle_rates = 1 / np.power(10000, (2 * (dimensions // 2)) / np.float32(dim))\n",
    "    angle_rads = positions * angle_rates\n",
    "\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    return tf.cast(angle_rads, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define TNT transformer block (Tokenized transformer block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tnt_transformer_block(inputs, num_heads, mlp_dim, dropout_rate):\n",
    "    attention_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=inputs.shape[-1])(inputs, inputs)\n",
    "    attention_output = layers.Dropout(dropout_rate)(attention_output)\n",
    "    attention_output = layers.LayerNormalization(epsilon=1e-6)(inputs + attention_output)\n",
    "\n",
    "    mlp_output = layers.Dense(mlp_dim, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(attention_output)\n",
    "    mlp_output = layers.Dropout(dropout_rate)(mlp_output)\n",
    "    mlp_output = layers.Dense(inputs.shape[-1])(mlp_output)\n",
    "    output = layers.LayerNormalization(epsilon=1e-6)(attention_output + mlp_output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the TNT Vision Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tnt_vision_transformer(num_patches, patch_dim, num_heads, mlp_dim, num_layers, num_classes, dropout_rate):\n",
    "    inputs = layers.Input(shape=(num_patches, patch_dim))\n",
    "    pos_encoding = positional_encoding(num_patches, patch_dim)\n",
    "    pos_encoding = tf.expand_dims(pos_encoding, 0)\n",
    "    x = inputs + pos_encoding\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        x = tnt_transformer_block(x, num_heads=num_heads, mlp_dim=mlp_dim, dropout_rate=dropout_rate)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Instantiate the TNT Vision Transformer\n",
    "num_patches = (32 // PATCH_SIZE) ** 2\n",
    "patch_dim = PATCH_SIZE * PATCH_SIZE * 3\n",
    "model = tnt_vision_transformer(\n",
    "    num_patches=num_patches,\n",
    "    patch_dim=patch_dim,\n",
    "    num_heads=4,\n",
    "    mlp_dim=128,\n",
    "    num_layers=3,\n",
    "    num_classes=10,\n",
    "    dropout_rate=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.001,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "# Wrap data augmentation for patches\n",
    "def augmented_patch_generator(datagen, x_data, y_data, patch_size):\n",
    "    for x_batch, y_batch in datagen.flow(x_data, y_data, batch_size=64):\n",
    "        yield extract_patches(x_batch, patch_size), y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    augmented_patch_generator(datagen, x_train, y_train, PATCH_SIZE),\n",
    "    validation_data=(val_patches, y_val),\n",
    "    steps_per_epoch=len(x_train) // 64,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('tnt_vision_transformer_model_optimized.h5')\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_patches, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(test_patches), axis=1)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=list(range(10)), yticklabels=list(range(10)))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=[str(i) for i in range(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Curve and AUC (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test, 10)\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(10):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_one_hot[:, i], model.predict(test_patches)[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "plt.figure()\n",
    "for i in range(10):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"Class {i} (AUC = {roc_auc[i]:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Each Class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
