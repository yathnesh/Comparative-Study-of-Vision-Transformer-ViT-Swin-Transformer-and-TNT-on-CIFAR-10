{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and preprocess the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to range [0, 1]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Split training set into training and validation sets\n",
    "val_size = int(0.2 * x_train.shape[0])\n",
    "x_val = x_train[:val_size]\n",
    "y_val = y_train[:val_size]\n",
    "x_train = x_train[val_size:]\n",
    "y_train = y_train[val_size:]\n",
    "\n",
    "# Define patch size\n",
    "PATCH_SIZE = 4  # Patch size for the Swin Transformer\n",
    "\n",
    "# Function to split an image into patches\n",
    "def extract_patches(images, patch_size):\n",
    "    batch_size = tf.shape(images)[0]\n",
    "    patches = tf.image.extract_patches(\n",
    "        images=images,\n",
    "        sizes=[1, patch_size, patch_size, 1],\n",
    "        strides=[1, patch_size, patch_size, 1],\n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding='VALID'\n",
    "    )\n",
    "    patch_dim = patch_size * patch_size * 3\n",
    "    patches = tf.reshape(patches, [batch_size, -1, patch_dim])\n",
    "    return patches\n",
    "\n",
    "# Apply patch extraction to training, validation, and test data\n",
    "train_patches = extract_patches(x_train, PATCH_SIZE)\n",
    "val_patches = extract_patches(x_val, PATCH_SIZE)\n",
    "test_patches = extract_patches(x_test, PATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swin Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinTransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, window_size=2, shift_size=1, dropout_rate=0.1):\n",
    "        super(SwinTransformerBlock, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.embed_dim = embed_dim\n",
    "        self.window_size = window_size\n",
    "        self.shift_size = shift_size\n",
    "        self.layernorm = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.msa = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.mlp = tf.keras.Sequential([\n",
    "            layers.Dense(4 * embed_dim, activation='relu'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Dense(embed_dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        x_norm = self.layernorm(x)\n",
    "        attn_output = self.msa(x_norm, x_norm)\n",
    "        x = x + attn_output\n",
    "        x_norm = self.layernorm(x)\n",
    "        x = x + self.mlp(x_norm)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swin Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_swin_transformer(input_shape, num_classes, num_blocks, embed_dim, num_heads):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Patch partition\n",
    "    x = layers.Dense(embed_dim)(inputs)\n",
    "    \n",
    "    # Swin transformer blocks\n",
    "    for _ in range(num_blocks):\n",
    "        x = SwinTransformerBlock(embed_dim, num_heads=num_heads)(x)\n",
    "    \n",
    "    # Global average pooling and classification\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patches = (32 // PATCH_SIZE) ** 2  # For CIFAR-10 with 32x32 images\n",
    "patch_dim = PATCH_SIZE * PATCH_SIZE * 3\n",
    "embed_dim = 64\n",
    "num_heads = 4\n",
    "num_blocks = 2\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Swin Transformer model\n",
    "model = build_swin_transformer(input_shape=(num_patches, patch_dim), num_classes=num_classes, num_blocks=num_blocks, embed_dim=embed_dim, num_heads=num_heads)\n",
    "\n",
    "# Compile the model\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.001,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Wrap data augmentation for patches\n",
    "def augmented_patch_generator(datagen, x_data, y_data, patch_size):\n",
    "    for x_batch, y_batch in datagen.flow(x_data, y_data, batch_size=64):\n",
    "        yield extract_patches(x_batch, patch_size), y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    augmented_patch_generator(datagen, x_train, y_train, PATCH_SIZE),\n",
    "    validation_data=(val_patches, y_val),\n",
    "    steps_per_epoch=len(x_train) // 64,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('swin_transformer_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_patches, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(test_patches), axis=1)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=list(range(10)), yticklabels=list(range(10)))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=[str(i) for i in range(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Curve and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_one_hot[:, i], model.predict(test_patches)[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "plt.figure()\n",
    "for i in range(num_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"Class {i} (AUC = {roc_auc[i]:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Each Class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
